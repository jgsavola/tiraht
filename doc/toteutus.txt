LZ78-algoritmin toteutus
========================


Pakkausalgoritmi
----------------

Projektin toteutus on edennyt vaiheittain. Ensimmäisessä vaiheessa
toteutin LZ78-pakkaus- ja purkualgoritmit merkkijonomuotoiselle
datalle. Sanakirjan tietorakenteena käytin Javan HashMap-rakennetta.
Algoritmin nopeudelle kriittiseksi osoittautui merkkijonojen
käsittely: kohtuullisen nopeuden saavuttamiseksi merkkijonojen
konkatenaatio piti korvata StringBuffer-luokan avulla.

Toisessa vaiheessa toteutin algoritmin tavumuotoiselle datalle. Odotin
suorituskyvyn paranevan, mutta ongelmaksi muodostui vaihtuvamittaisten
tavupuskurien toteuttaminen. Tätä varten tein ByteArray-luokan, joka
kasvattaa automaattisesti tavupuskuria. Ongelmaksi muodostui
hajautusfunktion toteuttaminen tavupuskurille, jonka lopussa saattaa
olla mielivaltainen määrä käyttämätöntä tilaa. Tämän ratkaisemiseen
käytin java.nio.ByteBuffer-luokkaa, jolla on mahdollista luoda useita
erilaisia näkymiä samaan fyysiseen muistialueeseen.

Näillä menetelmillä tavupohjaisen algoritmin suorituskyky kasvoi
samaan suuruusluokkaan kuin merkkijonoilla.

Kolmannessa vaiheessa korvasin koodauksessa käytetyn HashMap-rakenteen
uudella ByteTrie-rakenteella. ByteTrie käyttää avaimina
ByteArray-olioita ja arvoina kokonaislukuja. Koska Javassa ei voi
vapaasti tehdä osoittimia taulukkoon, osoittautui käytännölliseksi
käyttää listaiteraattoria avaimen tavujen iteraatioon. Ensimmäisessä
versiossa jokainen haku tehtiin Trien juuresta lähtien metodilla:

  int search(Iterator<Byte> key)

Tämä näkyi profiloinnissa syvänä rekursiona (avaimen pituuden mukaan,
suuruusluokka saattoi olla sadoissa tavuissa). Suorituskyky parani
huomattavasti, kun lisäsin uuden metodin

  ByteTrie retrieve(byte key)

Koska avainta haetaan iteratiivisesti kasvattaen hakuavainta
loppupäästä, voidaan hakua jatkaa siitä ByteTrien haarasta, johon
edellinen haku päättyi. Tämä korjasi pahimman suorituskykyongelman.

Ensimmäisessä ByteTrie-toteutuksessa lapsisolmujen säilytykseen käytin
javan TreeMap-rakennetta. Korvasin TreeMapin seuraavaksi
järjestämättömällä taulukolla. Tällöin taulukkoon lisääminen tapahtui
niin, että jos taulukossa oli tilaa, uusi lapsisolmu lisättiin
taulukon loppuun. Jos taas taulukko oli täynnä, muodostettiin uusi
suurempi taulukko ja vanhan taulukon alkiot kopioitiin uuteen.
Lisääminen tehtiin aina taulukon loppuun. Tällöin lapsisolmun
lisäämisen kuoletettu kustannus oli O(1). Lapsisolmujen haku oli
yksinkertainen lineaarinen haku, aikavaativuudeltaan O(n). Hieman
yllättäen kompression suorituskyky kasvoi n. 10% verrattuna
TreeMap-toteutukseen. Jos jätetään huomiotta bittikoodauksen vaatima
aika, suorituskyvyn kasvu oli kymmeniä prosentteja.

Seuraavassa versiossa lapsisolmut tallennettiin järjestettyyn
taulukkoon. Tällöin lisäämisen kuoletetuksi aikavaativuudes kasvoi
luokkaan O(n), mutta hakemisen puolestaan laski luokkaan O(log n).
Suorituskyvyn kasvu oli samaa luokkaa kuin edellisessä vaiheessa (n.
10% koko ohjelma, pelkkä LZ78 (arviolta) huomattavasti enemmän).



Kompressoidun datan koodaus
---------------------------

Jotta kompressiosta tavuvirraksi (tiedostoon) olisi tilahyötyä, täytyy
LZ78-pakkaajan tuottamat (etuliiteindeksi, jälkiliitetavu)-parit
koodata tiiviisti. Tähän kelpaa esimerkiksi etuliitekoodi, joista
yksinkertaisimmasta päästä lienee "General Unary"-koodi, joka
esitellään David Solomonin kirjasta "Data Compression. The Complete
Reference".

Luokat GeneralUnaryEncoder ja GeneralUnaryDecoder toteuttavat "General
Unary"-algoritmin. Koodaaminen tehdään biteittäin, joten tarvitaan
jokin keino kirjoittaa yksittäisiä bittejä. Tätä tarkoitusta varten on
toteutettu yksinkertaiset BitOutputStream ja BitInputStream-luokat.
Nämä luokat käyttävät yhden tavun puskuria lukemiseen ja
kirjoittamiseen.

Käytetyssä etuliitekoodauksessa on kolme parametria: start on
lyhyimmän koodin bittimäärä, step on koodin pituuden kasvatukseen
bittimäärä ja stop on pisimmän koodin bittimäärä. Optimaaliset
parametrit riippuvat koodattavien lukujen jakaumasta. Parilla
testiaineistolla tehtyjen kokeilujen perusteella LZ78 tuottamien
koodien todennäköisyys näyttää pienenenevän logaritmisesti
etuliiteindeksin funktiona (ks. histogrammi_alice.png ja
histogrammi_emacs.png). Hyvät parametrit testitiedostojen koodaukseen
löytyivät kokeilemalla.


Luokkarakenne
-------------

Kokeilujen myötä syntyi luokkarakenne, jossa ideana on käyttää
tulostus- ja syötevirtarajapintoja. Datavirta kulkee seuraavasti:

Kompressointi:

<lähtötiedosto>
  ==> InputStream
    ==> LZ78Compressor
      ==> LZ78TokenWriter
       (==> BitOutputStream)
          ==> OutputStream
            <pakattu tulostiedosto>

Dekompressointi:

<pakattu lähtötiedosto>
  ==> InputStream
   (==> BitInputStream)
      ==> LZ78TokenReader
        ==> LZ78Decompressor
          ==> OutputStream
            <purettu tulostiedosto>

Toteutettuja rajapintoja:

LZ78Compressor
  |
  -- LZ78ByteTrieCompressor (Kompressointi ByteTrie-rakenteen avulla.)

LZ78TokenWriter
  |
  -- LZ78ToArrayListEncoder (Tulostus: ArrayList<LZ78Token>-rakenne.)
  |
  |
  -- LZ78GeneralUnaryEncoder (Koodaus "General Unary"-menetelmällä,
  |                           kirjoitetaan tulostusvirtaan.)
  |
  -- LZ78NullEncoder (Koodeilla ei tehdä mitään.)

LZ78Decompressor
  |
  -- LZ78HashMapDecompressor (Dekompressointi HashMap-rakenteen avulla.)

LZ78TokenReader
  |
  -- LZ78FromIteratorDecoder (Luetaan Iterator<LZ78Token>-rakenteesta.)
  |
  -- LZ78GeneralUnaryDecoder (Luetaan "General Unary"-menetelmällä
                              koodattua bittivirtaa.)

Java vs C
=========

Javan muistinkäyttö jäi mietityttämään, joten tein yksinkertaisen
toteutuksen LZ78-pakkausalgoritmista ja trie-rakenteesta C:llä.
C-toteutus on suoraviivainen sovitus Java-toteutuksesta, joten
tietorakenteiden ja algoritmien pitäisi käyttäytyä samalla tavalla.
Erona on vain, että C:ssä muistinvaraus on toteutettu mallocilla ja
Javassa new:llä roskienkeruineen.

Suoraviivainen C-koodi olikin hieman nopeampi ja käytti hieman
vähemmän muistia kuin Java-toteutus. Ero ei kuitenkaan ollut erityisen
suuri: C-versio on n. 20% nopeampi ja muistinkäyttö oli n. 30%
pienempi (maxresident-arvo alla).

Java:

$ /usr/bin/time java -jar dist/tiraht.jar --test-compress -v testdata/emacs
testdata/emacs:                (sisään 10819544 tavua; ulos 1129636 koodia).
1.14user 0.07system 0:00.97elapsed 123%CPU (0avgtext+0avgdata 444688maxresident)k
0inputs+0outputs (0major+28148minor)pagefaults 0swaps

C:

$ /usr/bin/time ./c/tiraht_c testdata/emacs
sisään 10819544 tavua; ulos 1129636 koodia
0.77user 0.01system 0:00.79elapsed 98%CPU (0avgtext+0avgdata 315520maxresident)k
0inputs+0outputs (0major+19759minor)pagefaults 0swaps

C-toteutus:

* Pääohjelma:
  c/main.c

* LZ78-algoritmi (pakkaus):
  c/lz78.h
  c/lz78.c

* Trie-rakenne (avain tavujono, arvo kokonaisluku):
  c/trie.h
  c/trie.c

* malloc-kääreet:
  c/util.h
  c/util.c

* Makefile:

  c/Makefile

Kääntäminen:

  (cd c && make clean; make)

Käyttö:

  ./c/tiraht_c tiedosto1 [tiedosto2 ...]
